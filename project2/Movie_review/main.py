from fastapi import FastAPI
from pydantic import BaseModel
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# FastAPI ì•± ìƒì„±
app = FastAPI()

# -------------------- [ëª¨ë¸ ë¡œë”©] --------------------
# ì„œë²„ê°€ ì‹œì‘ë  ë•Œ ëª¨ë¸ì„ í•œ ë²ˆë§Œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
MODEL_NAME = "beomi/kcELECTRA-base-v2022"
MODEL_PATH = "./best_model_state.bin" # ì €ì¥ëœ ëª¨ë¸ íŒŒì¼ ê²½ë¡œ

# í† í¬ë‚˜ì´ì €ì™€ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)

# ì €ì¥ëœ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜(state_dict)ë¥¼ ë¶ˆëŸ¬ì™€ ì ìš©í•©ë‹ˆë‹¤.
model.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device('cpu')))
# CPUë¥¼ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •í•©ë‹ˆë‹¤. GPUì—ì„œ í•™ìŠµí–ˆë”ë¼ë„ CPU í™˜ê²½ì—ì„œ ì„œë¹™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
device = torch.device("cpu")
model.to(device)
model.eval() # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
# ----------------------------------------------------


# ì…ë ¥ ë°ì´í„° í˜•ì‹ì„ ì •ì˜í•˜ëŠ” Pydantic ëª¨ë¸
class SentimentRequest(BaseModel):
    text: str

# ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì •ì˜í•˜ëŠ” Pydantic ëª¨ë¸
class SentimentResponse(BaseModel):
    prediction: str
    probability: float


@app.get("/")
def read_root():
    return {"message": "Movie Review Sentiment Analysis API"}


@app.post("/predict", response_model=SentimentResponse)
def predict(request: SentimentRequest):
    # 1. ì…ë ¥ëœ í…ìŠ¤íŠ¸ë¥¼ ë°›ìŠµë‹ˆë‹¤.
    text = request.text
    
    # 2. í…ìŠ¤íŠ¸ë¥¼ í† í°í™”í•©ë‹ˆë‹¤.
    inputs = tokenizer(
        text,
        return_tensors="pt",
        max_length=128,
        padding="max_length",
        truncation=True
    )
    
    # 3. ëª¨ë¸ ì˜ˆì¸¡
    with torch.no_grad():
        inputs = {key: val.to(device) for key, val in inputs.items()}
        outputs = model(**inputs)
        
    # 4. ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í™•ë¥ ë¡œ ë³€í™˜í•˜ê³  í•´ì„í•©ë‹ˆë‹¤.
    logits = outputs.logits
    probs = torch.nn.functional.softmax(logits, dim=-1)
    
    # ê°€ì¥ í™•ë¥ ì´ ë†’ì€ í´ë˜ìŠ¤ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    prediction_idx = torch.argmax(probs).item()
    probability = probs[0, prediction_idx].item()
    
    prediction = "ê¸ì • ğŸ˜„" if prediction_idx == 1 else "ë¶€ì • ğŸ˜ "
    
    # 5. ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    return {
        "prediction": prediction,
        "probability": probability
    }